Бот для телеграмма, позволяющий преобразовывать одно изображение на основе стиля другого.
А также имеется возможность увеличения разрешения изображения. Все происходит с помощью нейронной сети

Пример входного изображения
<p align="center">
<img src="https://github.com/romegor/ml_tg_bot/blob/main/img/in1.jpg">
</p>

Пример изображения стиля
<p align="center">
<img src="https://github.com/romegor/ml_tg_bot/blob/main/img/style.jpg">
</p>

Пример изображения после обработки
<p align="center">
<img src="https://github.com/romegor/ml_tg_bot/blob/main/img/out1.jpg">
</p>


Сам проект разделен на 2 части - непосредственно реализация бота и сервер, отвечающий за обработку изображений и к которому обращается бот. Разделение необходимо, чтобы обеспечивать асинхронную работу бота (при синхронной по сути реализации переноса стиля), а также для более удобной реализации дополнительной функциональности в будущем в качестве rest-сервисов

## BOT

Бот реализован с использованием библиотеки <a href="https://github.com/aiogram/aiogram"> aiogram</a>. 
Необходим Python 3.7 и выше с [asyncio](https://docs.python.org/3/library/asyncio.html) и [aiohttp](https://github.com/aio-libs/aiohttp).

## Параметры (env)
* TOKEN - собственно токен бота
* ml_srv_ip - адрес ml_server, с которым будет общаться бот (по умолчанию "http://127.0.0.1")
* ml_srv_port - порт ml_server, с которым будет общаться бот (по умолчанию "5001")
* ml_srv_epoch - количество эпох обучения (по умолчанию 200)

Количество эпох влияет на качество переноса стиля, однако напрямую также влияет на время выполнения.
На GPU рекомендуется около 500-700 эпох (хотя можно и больше), на CPU - это будет ОЧЕНЬ долгий процесс, поэтому 200 эпох для демонстрации работы будет достаточно.

У бота стоит ограничение по времени на ответ от ml_server (20 минут)

## Запуск

Запускаете выполнение скрипта bot/main.py с заданными параметрами и бот готов к использованию



